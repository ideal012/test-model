import streamlit as st
import tempfile
import os

# Import ‡πÇ‡∏°‡∏î‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏≠‡∏á
from model import YoloSegmentationModel
from inference import run_inference
from utils import load_image_from_upload, draw_segmentation_results

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
st.set_page_config(page_title="AI Segmentation App", layout="wide")
st.title("üß© Modular AI Segmentation App")

# --- 1. Load Model Section ---
# ‡πÉ‡∏ä‡πâ @st.cache_resource ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏Ñ‡πà‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÑ‡∏°‡πà‡πÇ‡∏´‡∏•‡∏î‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°
@st.cache_resource
def get_loaded_model(pt_file_path):
    model_instance = YoloSegmentationModel()
    success = model_instance.load_weights(pt_file_path)
    if success:
        return model_instance
    else:
        return None

# Sidebar ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Config
# --- Sidebar Config ---
st.sidebar.header("‚öôÔ∏è Configuration")

MODEL_DIR = "models"

# ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå .pt ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå models ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
available_models = [
    f for f in os.listdir(MODEL_DIR) if f.endswith(".pt")
]

selected_model_name = st.sidebar.selectbox(
    "Select Model",
    available_models
)

conf_score = st.sidebar.slider("Confidence Score", 0.0, 1.0, 0.25)

# --- 2. Main Logic ---
if selected_model_name:

    model_path = os.path.join(MODEL_DIR, selected_model_name)

    model_wrapper = get_loaded_model(model_path)

    if model_wrapper:
        st.sidebar.success("‚úÖ Model Loaded!")
    else:
        st.sidebar.error("‚ùå Failed to load model.")
        st.stop()
        
    # --- 3. Image Input & Processing ---
    uploaded_image = st.file_uploader("Upload Image to Analyze", type=['jpg', 'png', 'jpeg'])

    if uploaded_image:
        col1, col2 = st.columns(2)
        
        # 3.1 ‡πÉ‡∏ä‡πâ function ‡∏à‡∏≤‡∏Å utils.py ‡πÅ‡∏õ‡∏•‡∏á‡∏†‡∏≤‡∏û
        original_img = load_image_from_upload(uploaded_image)
        
        with col1:
            st.info("Original Image")
            st.image(original_img, use_container_width=True)

        # ‡∏õ‡∏∏‡πà‡∏°‡∏Å‡∏î Predict
        if st.button("üîç Run Inference"):
            with st.spinner("Processing..."):
                try:
                    # 3.2 ‡πÉ‡∏ä‡πâ function ‡∏à‡∏≤‡∏Å inference.py ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
                    raw_results = run_inference(model_wrapper, original_img, conf_score)
                    
                    # 3.3 ‡πÉ‡∏ä‡πâ function ‡∏à‡∏≤‡∏Å utils.py ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏≤‡∏î‡∏†‡∏≤‡∏û‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                    result_img, found = draw_segmentation_results(original_img, raw_results)
                    
                    with col2:
                        if found:
                            st.success(f"Segmentation Complete!")
                        else:
                            st.warning("No objects found.")
                        
                        st.image(result_img, use_container_width=True)
                        
                except Exception as e:
                    st.error(f"Error during inference: {e}")

else:
    st.info("üëà Please upload a .pt model file in the sidebar to start.")
